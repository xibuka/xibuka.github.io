<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Wenhan blog</title>
    <link>https://wenhan.blog/</link>
    <description>Recent content on Wenhan blog</description>
    <image>
      <title>Wenhan blog</title>
      <url>https://wenhan.blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://wenhan.blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 May 2023 00:33:31 +0900</lastBuildDate><atom:link href="https://wenhan.blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kong Gatewayの JWT Pluginを使ってみる</title>
      <link>https://wenhan.blog/post/20230522_kong_jwt_plugin/</link>
      <pubDate>Mon, 22 May 2023 00:33:31 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230522_kong_jwt_plugin/</guid>
      <description>(https://tech.aufomm.com/how-to-use-jwt-plugin/ より翻訳)
Kongにはたくさんの認証プラグインがあります。今回はJWT Pluginの使い方についてお話したいと思います。
使用例 サービスを作成 1 2 3 4  curl -X POST http://localhost:8001/services \ -H &amp;#34;Content-Type: application/json&amp;#34; \ -H &amp;#34;Accept: application/json, */*&amp;#34; \ -d &amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;jwt-service&amp;#34;,&amp;#34;url&amp;#34;:&amp;#34;https://httpbin.org/anything&amp;#34;}&amp;#39;   Routeを作成 1 2 3 4  curl -X POST http://localhost:8001/services/jwt-service/routes \ -H &amp;#34;Content-Type: application/json&amp;#34; \ -H &amp;#34;Accept: application/json, */*&amp;#34; \ -d &amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;jwt-route&amp;#34;,&amp;#34;paths&amp;#34;:[&amp;#34;/jwt&amp;#34;]}&amp;#39;   curl &#39;http://localhost:8000/jwt&#39; -i でルートにアクセスすると、HTTP/1.1 200 OKとなるはずです。
JWT Pluginを有効 :::note このプラグインは、Service単位またはグローバル全体に有効化することも可能です。 :::
1 2 3 4  curl --request POST \ --url http://localhost:8001/plugins \ --header &amp;#39;Content-Type: application/x-www-form-urlencoded&amp;#39; \ --data name=jwt   上記のルートをもう一度アクセスすると、HTTP/1.</description>
    </item>
    
    <item>
      <title>Secure deployment Kong Gateway using Mozila SOPS, age and Github Action</title>
      <link>https://wenhan.blog/post/20230308_using-sops-and-age-deploy-konggw_en/</link>
      <pubDate>Thu, 09 Mar 2023 16:41:18 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230308_using-sops-and-age-deploy-konggw_en/</guid>
      <description>Background When deploying Kong Gateway, there is some data that we do not want to store in plain text, such as connection information to the database. The Kong Secret Manager was developed to solve this problem, which can be solved using a 3rd party service such as AWS Secrets Manager. However, this functionality is unavailable when the environment does not allow connection to external security services. In this case, we can use a encryption tool SOPS, developed by Mozilla to do the encryption and decryption.</description>
    </item>
    
    <item>
      <title>Mozila SOPS&#43;ageで実現するKong Gatewayセキュアデプロイメント</title>
      <link>https://wenhan.blog/post/20230308_using-sops-and-age-deploy-konggw/</link>
      <pubDate>Wed, 08 Mar 2023 16:41:18 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230308_using-sops-and-age-deploy-konggw/</guid>
      <description>背景 Kong Gatewayをデプロイする時に、データベースへの接続情報など平文で保存したくないデータが存在しています。これを解決するためにKong Secret Managerが開発され、AWS Secrets Managerなどの3rdパーティのサービスを利用すれば解決できます。しかし、環境によって外部のセキュリティサービスに接続できない時にこの機能は利用できません。ここで、Mozilaが開発したSOPSという暗号化ツールとGithub ActionのCI/CD workflowを利用し、普段暗号化されている設定ファイルをデプロイ時だけ復号し、Kong GWをインストールする実現することができました。
事前準備 CI/CD workflowを構築する前に、まずはローカル環境で暗号と復号を試してみましょう。以下の必要なツールをローカル環境にインストールします。
 age sops  SOPSはとても便利な暗号化・復号化のツールで人気があります。PGP, age, Google cloud&amp;rsquo;s KMS, Azure&amp;rsquo;s key valut, Hashicorp Vaultなどをサポートしています。今回は他のクラウドサービスを極力利用しない方針のため、ageを選択しました。
ツールのインストールができましたら、age-kengen --helpを試してみましょう。
1 2 3 4 5 6 7 8  $ age-keygen --help Usage: age-keygen [-o OUTPUT] age-keygen -y [-o OUTPUT] [INPUT] Options: -o, --output OUTPUT Write the result to the file at path OUTPUT. -y Convert an identity file to a recipients file.</description>
    </item>
    
    <item>
      <title>HashiCorp Vaultを参照しKongGatewayをデプロイ</title>
      <link>https://wenhan.blog/post/20230223_vault_konggwdeploy_via_sm/</link>
      <pubDate>Thu, 23 Feb 2023 00:34:38 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230223_vault_konggwdeploy_via_sm/</guid>
      <description>背景 Kong Gateway 3.0 から、Secrets ManagementがGAとなりました。Kong Gateway は、データベースのパスワードからプラグインで使用される API キーまで、多くのSecretに依存して動作します。以前ではRBACを使って、Admin APIとKong Managerから機密情報へのアクセスを制限できましたが、Secretを平文で表示されずに管理できたら嬉しいですよね。これを実現できるのはSecrets Managementです。
サポートするVault 現時点で、サポートしているVaultは以下の４種類です。
 AWS Secrets Manager GCP Secrets Manager HashiCorp Vault Environment Variable  Kong は、上記の各システムを抽象化して、利用するときにVaultのキーワード(hcv、aws、gcpまたは env)を変更するだけで利用できます。たとえば、HashiCorp Vaultの Postgres Secretのpassword フィールドにアクセスするには、次のフォーマットで参照できます。
{vault://hcv/postgres/password}  AWS Secrets Managerの場合
{vault://aws/postgres/password}  環境変数の場合
export POSTGRES=&#39;{&amp;quot;username&amp;quot;:&amp;quot;user&amp;quot;, &amp;quot;password&amp;quot;:&amp;quot;pass&amp;quot;}&#39; {vault://env/postgres/password}  デモ では実際にSecrets Managementを使ってVaultのSecretsを参照し、Kongのデプロイを試してみよう
Vault環境を用意 ここで、TOKEN_IDをkongにします。この値は後の認証するときに使用されます。
1 2 3 4 5 6  docker run -d --name vault.idp \ --network=kong-net \ -e &amp;#34;VAULT_DEV_ROOT_TOKEN_ID=kong&amp;#34; \ -p 8200:8200 \ --cap-add=IPC_LOCK \ vault:latest   Secretを作成 コンテナーに入って、Secretを作成しましょう</description>
    </item>
    
    <item>
      <title>Kong Gatewayで実装！リクエストが失敗したらSlackWebhookで通知</title>
      <link>https://wenhan.blog/post/20230220_exit_slack/</link>
      <pubDate>Mon, 20 Feb 2023 14:21:23 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230220_exit_slack/</guid>
      <description>背景 Kong Gatewayを使ってAPIにアクセスする時には、もしリクエストが失敗したら通知して欲しいですね。通常のやり方はLog系のプラグインでLogを保存してから、3rd partyの製品（ELK）でAlertを設定して通知することです。でも他の製品を使うとデプロイも面倒だし、ライセンスや設定内容も必要だし、できればKong内部で実現したいな。。という要望があると思います。 今回は、Exit Transformer プラグインを使って、リクエストがエラーだったらLuaスクリプトでSlack Webhookを叩くことをメモします。このプラグインは、Lua 関数を使用して、Kong 応答終了メッセージを変換およびカスタマイズすることができます。メッセージ、ステータスコード、ヘッダーの変更から、Kong 応答の構造の完全な変換まで、さまざまな機能があります。
プラグインを試す まずはページ上にある例を試してみよう。
サービスとルートを作成 1 2  $ http :8001/services name=example.com host=mockbin.org $ http -f :8001/services/example.com/routes hosts=example.com   失敗させるため key auth プラグインを実装 1  $ http :8001/services/example.com/plugins name=key-auth   Luaスクリプトを作成 以下のコードでは、x-some-headerのヘッダーを追加し、メッセージの最後に, arrを追加した。 この内容をtransform.luaとして保存する。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  -- transform.lua return function(status, body, headers) if not body or not body.</description>
    </item>
    
    <item>
      <title>Kong GatewayのPlugin Ordering機能を試す</title>
      <link>https://wenhan.blog/post/20230127_plugin_ordering/</link>
      <pubDate>Fri, 27 Jan 2023 11:42:28 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20230127_plugin_ordering/</guid>
      <description>Kong GatewayのPoCをやっている時に、ある問題に遭いました。 PoCの要件は以下になる
 Key-authプラグインでGateway全体を保護 Request-transformerプラグインで必要なAPI KeyをHeaderに付与し認証を突破  二つのプラグインを設定した後、API keyをrequestに追加されても認証されない
1 2 3 4 5 6 7 8 9 10 11  # key-auth is enabled ❯ http --header localhost:8000/demo | head -1 HTTP/1.1 401 Unauthorized # Got 401 after creating request-transformer-adv plugin. ❯ curl -X POST http://localhost:8001/services/testsvc/plugins \ --data &amp;#34;name=request-transformer-advanced&amp;#34; \ --data &amp;#34;config.add.headers=apikey:wenhandemo&amp;#34; ... ❯ http --header localhost:8000/demo | head -1 HTTP/1.1 401 Unauthorized   理由を調べたら、どうやらPluginのデフォルトの実行順番があるらしいです。
https://docs.konghq.com/gateway/latest/plugin-development/custom-logic/#plugins-execution-order
key-authのプライオリティは1250、request-transformer-advの801より高いです。よってkey-authが実行するときに、Headerに必要なAPI Keyがまだ付与されていない状態になります。</description>
    </item>
    
    <item>
      <title>Kong GatewayのWebhook/event hookを試した</title>
      <link>https://wenhan.blog/post/20221122_event-hooks/</link>
      <pubDate>Tue, 22 Nov 2022 22:57:09 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20221122_event-hooks/</guid>
      <description>Event Hooks機能を利用することで、Kong Gatewayで特定のイベントが発生したときに通知を受け取ることができます。新しい管理者やサービスを作成したり、プラグインによる制限が有効になったりすることを監視したい場合に役に立ちます。
どのような機能? Event Hooksには以下の４種類があります。
 webhook: 定義されたフォーマットのPOSTリクエストを送信 webhook-custom: カスタムしたHTTPリクエストを送信 log: Eventの内容をKong Gatewayのエラーログに記録 lambda: 事前に用意したLua関数を起動  ここでは、Webhook-customとlogを試していきます。
利用可能なEventを確認 Kong Gateway は adminAPIの/event-hooks/sources エンドポイントを提供します。ここから利用できるソース、Eventとパラメータを確認することができます。データが大量にあるので、一部抜粋で説明します。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ... &amp;#34;rate-limiting-advanced&amp;#34;: { &amp;#34;rate-limit-exceeded&amp;#34;: { &amp;#34;fields&amp;#34;: [ &amp;#34;consumer&amp;#34;, &amp;#34;ip&amp;#34;, &amp;#34;service&amp;#34;, &amp;#34;rate&amp;#34;, &amp;#34;limit&amp;#34;, &amp;#34;window&amp;#34; ], &amp;#34;unique&amp;#34;: [ &amp;#34;consumer&amp;#34;, &amp;#34;ip&amp;#34;, &amp;#34;service&amp;#34; ], &amp;#34;description&amp;#34;: &amp;#34;Run an event when a rate limit has been exceeded&amp;#34; } }, .</description>
    </item>
    
    <item>
      <title>Kong Managerをホストネームでデプロイための設定</title>
      <link>https://wenhan.blog/post/20220906_gettingkongmanagertowork/</link>
      <pubDate>Wed, 07 Sep 2022 00:40:42 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20220906_gettingkongmanagertowork/</guid>
      <description>NOTE: https://svenwal.de/blog/20210316_kong_manager_install/ より翻訳
 TL;DR: Kong Managerが動作しない場合は、KONG_ADMIN_API_URIとKONG_ADMIN_GUI_URLの設定を確認してください。
Kong Managerの紹介 2021年2月より、Kong Manager（長年Kong Enterpriseの機能でした）はKongの無料版の一部となりました。
私は長い間Kong Managerを使用しており、多くのユーザーが正しくセットアップするのを助けてきましたので、幾つの典型的な設定の問題を共有したいと思います。
Kong Managerは利用しやすい Kong Managerはout of the boxでありすぐに使えます。ローカル マシンに Kong (Free または Enterprise) をインストールし、有効にすると、 http://localhost:8002でKong Managerをすぐアクセスできます。
壊れ方 (直し方) 実際のインストールでは、Kong Managerを適当なローカルマシンに置くのではなく、サーバーにインストールし、適切なDNSエントリを使ってアクセスする必要があります。そして、そうしている間、8002のようなポートを持つのではなく、異なるホストネームを使用したいのです。
それでは、KongはLoadBalancer/Ingress/&amp;hellip;の後ろにインストールされ、Kong Managerをhttps://kong-manager.my-company.example.comのような素敵なホスト名でを公開していると仮定しましょう。これを開くと、Kongマネージャが表示されますが、デフォルトのワークスペースは消えていて、新しいワークスペースを作成するボタンもありません。では、何が起こったのでしょうか？
KongのすべてがAPIであり、Kong Managerのユーザーインターフェイス全体が、ローカルのブラウザで動作するブラウザベースのアプリケーションであリます。そして、設定を変更していない場合、デフォルトのAdmin-APIアドレス（http://localhost:8001）への呼び出しが開始されます。
KongはAdmin-APIの外部URLを知ることができないため、設定でそれを指定する必要があります。例えば、8001-Portをhttps://kong-admin.my-company.example.com のようにマッピングしたとすると、次のように設定する必要があります。
1  admin_api_uri = https://kong-admin.my-company.example.com  または（環境変数を使用している場合）
1  kong_admin_api_uri = https://kong-admin.my-company.example.com  これで、ブラウザはAdmin APIがどこにあるかを知り、呼び出しを開始するようになりました。しかし、実際に試してみると、やはりうまくアクセスできません。では、何が足りないのでしょうか？
私たちはKong ManagerとAdmin APIに異なるホスト名を作成しましたが、これはブラウザのCORS保護をトリガーします。https://kong-manager.my-company.example.com 上の JavaScript は https://kong-admin.my-company.example.com への呼び出しを試み、ブラウザはそれを拒否します（クロスオリジンのため）。そこで、第二段階として、Admin-API が正しい Allow-Origin-Header を送信しているかどうかを確認する必要があります。そのためには、Kong ManagerのURLがどのようなものであるかをKongに伝える必要があります。
1  admin_gui_url = https://kong-manager.</description>
    </item>
    
    <item>
      <title>Kong Gatewayの Route By Header Pluginを使ってみる</title>
      <link>https://wenhan.blog/post/20220802_using-kong-gw-route-by-header-plugin/</link>
      <pubDate>Wed, 03 Aug 2022 01:19:02 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20220802_using-kong-gw-route-by-header-plugin/</guid>
      <description>紹介 Kong GatewayではRouteでサブパスを定義し、どのServiceにアクセスするかを決めています。例えば、以下のURLの後ろのサブパスがpathAの場合は、トラフィックがserviceAにルーティングされ、最終的に後ろにあるendpointAにアクセスされます。
1  http://mykong.org:8000/pathA =&amp;gt; serviceA =&amp;gt; endpointA   しかし、サブパスではなくて、もっと動的にリクエストの転送先を決めたい場合があります。このプラグインは、事前に定義されたヘッダーと転送先をルールに、リクエストヘッダ情報を見て転送先を決めています。ルールに二つのパラメータがあり、conditionは定義したヘッダーと値、upstream_nameは転送先のUpstreamオブジェクトです。
1  {&amp;#34;rules&amp;#34;:[{&amp;#34;condition&amp;#34;: {&amp;#34;location&amp;#34;:&amp;#34;us-east&amp;#34;}, &amp;#34;upstream_name&amp;#34;: &amp;#34;east.doamin.com&amp;#34;}]}   この記事では、このプラグインの実装についてメモします。 注：このプラグインを操作できるのはAdmin APIを通す方法のみ。Kong Managerでの操作はできない。
https://docs.konghq.com/hub/kong-inc/route-by-header/
デモ 実際にこのプラグインを使ってみましょう。まずは作業用のserviceとrouteを作成する。serviceのendpointはhttp://httpbin.org/anything となりますが、このプラグインのルールに当てはまらない時にアクセスされます。
1 2 3 4 5 6 7 8 9 10  curl -i -X POST http://localhost:8001/services \  --data protocol=http \  --data host=httpbin.org \  --date path=/anything --data name=demo curl -i -X POST http://localhost:8001/routes \  --data &amp;#34;paths[]=/&amp;#34; \  --data service.</description>
    </item>
    
    <item>
      <title>KongのCanary Release pluginを使ってみる</title>
      <link>https://wenhan.blog/post/20220531_using-kong-canary-release-plugin/</link>
      <pubDate>Tue, 31 May 2022 13:58:39 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20220531_using-kong-canary-release-plugin/</guid>
      <description>紹介 Kong Gatewayのプラグインを利用すれば、カナリアリリースが簡単に設定することができます。しかもカナリアリリースのモードは単なるパーセンテージではなく、徐々に利用拡大や、Writelist&amp;amp;blacklistの設定もできます。
この記事では、カナリアリリースのやり方についてメモします。
https://docs.konghq.com/hub/kong-inc/canary/
ServiceとRouteの作成 デモの例として、現在のバージョンをhttp://httpbin.org/xmlに、新規リリースのバージョンをhttp://httpbin.org/jsonにします。なので、現在のバージョンの場合は、xmlのレスポンス、新規リリースのバージョンの場合は、jsonのレスポンスが帰ってくるはず。
1 2 3 4 5 6 7  ❯ http POST localhost:8001/services \ name=canary-api-service \ url=http://httpbin.org/xml ❯ http -f POST localhost:8001/services/canary-api-service/routes \ name=canary-api-route \ paths=/api/canary   動作確認、xmlのレスポンスが帰ってきた。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  ❯ http GET localhost:8000/api/canary HTTP/1.</description>
    </item>
    
    <item>
      <title>Kongの Mocking Plugingを使ってみる</title>
      <link>https://wenhan.blog/post/20220517_using-kong-mocking-plugin/</link>
      <pubDate>Tue, 17 May 2022 13:58:39 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20220517_using-kong-mocking-plugin/</guid>
      <description>紹介 Mockingプラグインは、開発中のAPIに対するテストを行うために、模擬のエンドポイントを提供するものです。Open API（OAS）仕様に基づいて、APIに送信されたリクエストに模擬応答をレスポンスします。また、テストの柔軟性のため、Mockingプラグインを簡単に有効または無効にすることができます。 https://docs.konghq.com/hub/kong-inc/mocking/
注意点として、このプラグインは、200、201と204の応答をレスポンスすることができます。正常動作をテストするために開発されたもので、200番台以外のコードをを返すことができません。
今回は、db-less環境のKong-gatewayをDocker containerで構築し、その上に Mocking Pluginを試してみます。
Kong-gatewayをデプロイする前に db-lessの環境のため、Admin APIやGUIで設定を変更することはできません（保存先はないから）。そのため、起動時にDeclarative Configurationという名の設定ファイルを事前にコンテナーに食わせる必要があります。
https://docs.konghq.com/gateway/2.8.x/reference/db-less-and-declarative-config/#main
今回の目標は Mockingを試したいので、 Mockingの設定内容も事前にこのファイルに記述していきます。Mocking Pluginの紹介ページで書いたように、設定自体はとてもシンプルです。ただ、肝心なのはapi_specificationとapi_specification_filenameの二つです。この二つのパラメータは、模擬のエンドポイントのスペック内容を定義するために使われますが、違いは以下の通りです。
 api_specification_filename: スペック内容が保存されたファイル名を設定する。 api_specification: スペック内容をそのままパラメータに設定する。  api_specification_filenameは、設定するファイルを事前にDev Portalにアップロードしてから、パスなしで設定してください。設定の例はここに書いています。しかし、今回はdb-lessの環境を構築するため、そもそもdev protalが利用できないし、api_specification_filenameを利用できません。
そのため、api_specificationにサンプルのAPIのスペック内容をそのまま設定し、コンテナーを立ち上げます。スペックのサンプルは、Mocking Pluginの紹介ページにあります。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  _format_version:&amp;#34;1.1&amp;#34;_transform:trueservices:- host:mockbin.orgname:example_serviceport:80protocol:httproutes:- name:example_routepaths:- /mockstrip_path:trueplugins:- name:mockingconfig:api_specification:&amp;#39;{&amp;#34;swagger&amp;#34;:&amp;#34;2.0&amp;#34;,&amp;#34;info&amp;#34;:{&amp;#34;title&amp;#34;:&amp;#34;Stock API&amp;#34;,&amp;#34;description&amp;#34;:&amp;#34;Stock Information Service&amp;#34;,&amp;#34;version&amp;#34;:&amp;#34;0.1&amp;#34;},&amp;#34;host&amp;#34;:&amp;#34;127.0.0.1:8000&amp;#34;,&amp;#34;basePath&amp;#34;:&amp;#34;/&amp;#34;,&amp;#34;schemes&amp;#34;:[&amp;#34;http&amp;#34;,&amp;#34;https&amp;#34;],&amp;#34;consumes&amp;#34;:[&amp;#34;application/json&amp;#34;],&amp;#34;produces&amp;#34;:[&amp;#34;application/json&amp;#34;],&amp;#34;paths&amp;#34;:{&amp;#34;/stock/historical&amp;#34;:{&amp;#34;get&amp;#34;:{&amp;#34;description&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;operationId&amp;#34;:&amp;#34;GET /stock/historical&amp;#34;,&amp;#34;produces&amp;#34;:[&amp;#34;application/json&amp;#34;],&amp;#34;tags&amp;#34;:[&amp;#34;Production&amp;#34;],&amp;#34;parameters&amp;#34;:[{&amp;#34;required&amp;#34;:true,&amp;#34;in&amp;#34;:&amp;#34;query&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;tickers&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;string&amp;#34;}],&amp;#34;responses&amp;#34;:{&amp;#34;200&amp;#34;:{&amp;#34;description&amp;#34;:&amp;#34;Status 200&amp;#34;,&amp;#34;examples&amp;#34;:{&amp;#34;application/json&amp;#34;:{&amp;#34;meta_data&amp;#34;:{&amp;#34;api_name&amp;#34;:&amp;#34;historical_stock_price_v2&amp;#34;,&amp;#34;num_total_data_points&amp;#34;:1,&amp;#34;credit_cost&amp;#34;:10,&amp;#34;start_date&amp;#34;:&amp;#34;yesterday&amp;#34;,&amp;#34;end_date&amp;#34;:&amp;#34;yesterday&amp;#34;},&amp;#34;result_data&amp;#34;:{&amp;#34;AAPL&amp;#34;:[{&amp;#34;date&amp;#34;:&amp;#34;2000-04-23&amp;#34;,&amp;#34;volume&amp;#34;:33,&amp;#34;high&amp;#34;:100.75,&amp;#34;low&amp;#34;:100.87,&amp;#34;adj_close&amp;#34;:275.03,&amp;#34;close&amp;#34;:100.03,&amp;#34;open&amp;#34;:100.87}]}}}}}}},&amp;#34;/stock/closing&amp;#34;:{&amp;#34;get&amp;#34;:{&amp;#34;description&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;operationId&amp;#34;:&amp;#34;GET /stock/closing&amp;#34;,&amp;#34;produces&amp;#34;:[&amp;#34;application/json&amp;#34;],&amp;#34;tags&amp;#34;:[&amp;#34;Beta&amp;#34;],&amp;#34;parameters&amp;#34;:[{&amp;#34;required&amp;#34;:true,&amp;#34;in&amp;#34;:&amp;#34;query&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;tickers&amp;#34;,&amp;#34;type&amp;#34;:&amp;#34;string&amp;#34;}],&amp;#34;responses&amp;#34;:{&amp;#34;200&amp;#34;:{&amp;#34;description&amp;#34;:&amp;#34;Status 200&amp;#34;,&amp;#34;examples&amp;#34;:{&amp;#34;application/json&amp;#34;:{&amp;#34;meta_data&amp;#34;:{&amp;#34;api_name&amp;#34;:&amp;#34;closing_stock_price_v1&amp;#34;},&amp;#34;result_data&amp;#34;:{&amp;#34;AAPL&amp;#34;:[{&amp;#34;date&amp;#34;:&amp;#34;2000-06-23&amp;#34;,&amp;#34;volume&amp;#34;:33,&amp;#34;high&amp;#34;:100.75,&amp;#34;low&amp;#34;:100.87,&amp;#34;adj_close&amp;#34;:275.03,&amp;#34;close&amp;#34;:100.03,&amp;#34;open&amp;#34;:100.87}]}}}}}}}}}&amp;#39;max_delay_time:1min_delay_time:0.001random_delay:false  db-lessのKong-gateway環境を構築 ライセンスを環境変数に設定した後、以下のコマンドでコンテナーを立ち上げます。KONG_DATABASEがoffになっているところと、KONG_DECLARATIVE_CONFIGに設定ファイルのパスが書かれているところが重要です。設定ファイルは、-vでローカルからMountされています。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  $ docker run -d --name kong-dbless \  --network=kong-net \  -v &amp;#34;$(pwd):/kong/declarative/&amp;#34; \  -e &amp;#34;KONG_DATABASE=off&amp;#34; \  -e &amp;#34;KONG_DECLARATIVE_CONFIG=/kong/declarative/kong.</description>
    </item>
    
    <item>
      <title>Access K3s From Outside</title>
      <link>https://wenhan.blog/post/access-k3s-from-outside/</link>
      <pubDate>Thu, 03 Mar 2022 23:49:19 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/access-k3s-from-outside/</guid>
      <description>Access k3s cluster from outside When you have created a k3s cluster with the default settings, it only can be access inside the node where you&amp;rsquo;re using. Bring the kubeconfig file /etc/rancher/k3s/k3s.yaml outside the node and import it to another host, you will get below issue when trying to access.
1 2  ❯ kubectl get node Unable to connect to the server: x509: certificate is valid for 10.0.140.68, 10.43.0.1, 127.</description>
    </item>
    
    <item>
      <title>--node-cidr-mask-sizeエラーの原因と修正</title>
      <link>https://wenhan.blog/post/20220126_--node-cidr-mask-size_error/</link>
      <pubDate>Wed, 26 Jan 2022 11:33:00 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20220126_--node-cidr-mask-size_error/</guid>
      <description>rkeクラスタのcidrを弄ったら、以下のようなエラーが出てクラスタの作成が失敗した。
1  {&amp;#34;log&amp;#34;:&amp;#34;F1203 01:36:22.168496 1 node_ipam_controller.go:115] Controller: Invalid --cluster-cidr, mask size of cluster CIDR must be less than or equal to --node-cidr-mask-size configured for CIDR family\n&amp;#34;,&amp;#34;stream&amp;#34;:&amp;#34;stderr&amp;#34;,&amp;#34;time&amp;#34;:&amp;#34;2021-12-03T01:36:22.16859524Z&amp;#34;}   cluster.yamlの関連部分は以下のようになっています。
1 2 3 4 5 6  services:kube-controller:cluster_cidr:10.42.0.0/25service_cluster_ip_range:10.43.0.0/25kube-api:service_cluster_ip_range:10.43.0.0/25  問題になる場所はCIDRのマスクサイズです。このマスクサイズは--node-cidr-mask-sizeで設定され、クラスタのCIDRのマスクサイズより大きく（IP範囲が少なく）なる必要があります。デフォルトは24のため、上記の設定の25より小さい（IP範囲が溢れた）のでエラーとなりました。
この--node-cidr-mask-sizeは、以下のようにextra_argsで変更することができます。
1 2 3 4 5 6  services:kube-controller:cluster_cidr:10.42.0.0/25service_cluster_ip_range:10.43.0.0/25extra_args:node-cidr-mask-size:25  25, 26のような数字に設定したら、クラスタの作成ができるようになります。
このマスクサイズとノードあたりで利用できるPod数の関係として、Pod の追加 / 削除などを考慮し、確保したIPアドレスの数の半分ぐらいが実際に作成できるPodの数となります。
例えば、cluster_cidrのマスクが25なので、クラスタレベルのIPアドレス数は128個です。
1ノードの場合、--node-cidr-mask-sizeを同じく25を設定したら128個のIPアドレスが確保され、33～64のPodが作成できます。
3ノードの場合、ノードあたりのIP数は42個までしか使えなくて、--node-cidr-mask-sizeを27に設定しなければいけません。そうすると、Pod数は 9～16になります。 システムレベルのPod（corednsなど）も10個程度あるので、28にしたら業務Pod用のIPアドレスが足りなくなります。
また、上記にあわせてmax-podsの設定も必要です。
1 2 3  kubelet:extra_args:max-pods:40  参考まで https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr</description>
    </item>
    
    <item>
      <title>RancherのContinuous Delivery機能で簡単GitOpsを実現できる</title>
      <link>https://wenhan.blog/post/20211111_fleet-demo/</link>
      <pubDate>Thu, 11 Nov 2021 16:18:38 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/20211111_fleet-demo/</guid>
      <description>この記事では、Single nodeのRancher server と二つのk3sクラスタ環境を構築し、 そRancherのContinuous Delivery機能で、二つのk3sクラスタをGitOpsで操作します。
Step 1: Deploying a Rancher Server まずはrancherノードで、以下のdocker コマンドを実行しSingle nodeのRancher serverを構築します。
1 2 3 4  sudo docker run -d --restart=unless-stopped \ -p 80:80 -p 443:443 \ --privileged \ rancher/rancher:v2.5.10   Rancher serverが1分程度で立ち上がりますので、rancherノードのIPアドレスをブラウザで開いてRancher UIをアクセスしてください。
今回の場合、Rancherは自己署名証明書を使用しているため、ブラウザに証明書の警告が表示されます。この警告はスキップしても問題ありません。 また、一部のブラウザでは、スキップボタンが表示されない場合があります。 この場合は、エラーページの任意の場所をクリックして、thisisunsafeと入力します。 これにより、ブラウザは警告をバイパスして証明書を受け入れるようになります。
初回アクセスの時パスワードの初期設定が必要です。画面のガイドに従って設定してください。
Step 2: Deploy k3s Kubernetes Cluster 次はk3sクラスタをデプロイします。手順はとても簡単で、以下のコマンドをk3s-1とk3s-2ノードで実行するだけです。
後でアップグレードもやる予定なので、ここではあえてちょっと古いバージョンを指定しk3sのクラスタをデプロイします。
k3s-1 1  sudo curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.19.15+k3s2 sh -   k3s-2 1  sudo curl -sfL https://get.</description>
    </item>
    
    <item>
      <title>kubernetes証明書期限切れのテスト</title>
      <link>https://wenhan.blog/post/modify-kubeadm-cert-expired-period-test/</link>
      <pubDate>Wed, 23 Jun 2021 17:34:31 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/modify-kubeadm-cert-expired-period-test/</guid>
      <description>仕事の関係で、期限切れのkubernetesクラスタの証明書更新の手順を検証することになった。 今まで特にやったことないので記録しておきます。
kubeadmのソースを変更しビルド  ビルド環境にgoとgitをインストールし、goの実行パスをPATHに追加
  kubernetesのソースコードをダウンロード、今回はv1.18.18を利用
git clone -b v1.18.18 https://github.com/kubernetes/kubernetes
  以下の通りでファイルを修正するし、証明書の有効期限を10分にする
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  diff --git a/cmd/kubeadm/app/constants/constants.go b/cmd/kubeadm/app/constants/constants.go index b56891ca908..eed934280e7 100644 --- a/cmd/kubeadm/app/constants/constants.go +++ b/cmd/kubeadm/app/constants/constants.go @@ -46,7 +46,8 @@ const ( TempDirForKubeadm = &amp;#34;tmp&amp;#34; // CertificateValidity defines the validity for all the signed certificates generated by kubeadm - CertificateValidity = time.</description>
    </item>
    
    <item>
      <title>Rancher ゼロから勉強 </title>
      <link>https://wenhan.blog/post/rancher-learning-from-zero/</link>
      <pubDate>Tue, 09 Jun 2020 16:12:08 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/rancher-learning-from-zero/</guid>
      <description>紹介 Rancherはrancher-server とrancher-agent、そして一つ以上のkubernetes clusterによって構成されている。この中、rancher-agentは管理されたkubernetesに実行され、rancher-serverと通信し、クラスタの情報を送信する。
rancher-serverはkubernetesを管理するためのWebUIとAPIを提供している。rancher-serverはHTTPSのみアクセスできる。
インストール シングルノード シングルノードの構築は以下二つの方法があります。
 dockerで直接rancher-serverを実行 rkeで一つのノードに全てのroleを有効  rkeの方法は後でも出てくるので割愛、ここではdockerの方法を示す。
rancher-serverを実行したいノードで、下記のコマンドを入力する。
1 2 3  docker run -d --restart=unless-stopped \  -p 80:80 -p 443:443 \  rancher/rancher:latest   これでシングルノードのrancher-serverを起動した。http://&amp;lt;IP Address&amp;gt;でアクセスできる。
マルチノード rkeを使ってHA環境のrancher-serverを構築する。
rke(rancher k8s engine)はkubernetesを構築するためのコマンドで、環境を用意すればコマンド一つでクラスターを構築できる。
マシンの用意 今回はmultipass でマシンを準備する。以下のコマンドで６台の仮想マシンを作成する。
1 2 3 4 5 6  multipass launch -c 2 -m 4096M -d 20G --cloud-init=./cloud-init.yaml -n kmaster1 multipass launch -c 2 -m 4096M -d 20G --cloud-init=./cloud-init.yaml -n kmaster2 multipass launch -c 2 -m 4096M -d 20G --cloud-init=.</description>
    </item>
    
    <item>
      <title>Install Linux OS With Qemu CLI</title>
      <link>https://wenhan.blog/post/install-linux-os-with-qemu-cli/</link>
      <pubDate>Wed, 15 Apr 2020 12:08:11 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/install-linux-os-with-qemu-cli/</guid>
      <description>Background Sometimes you want to build a reproducer for some installation issues. Instead of putting the actual CD-ROM in your machine, QEMU, a popular hardware virtualization solution, could help you to test it on virtual machines. Qemu can help you to do a GUI install with Desktop or live Server install ISO, or use text-mode installation with a Server install CD.
Install 1  $ sudo apt install qemu   And also you need a ISO for installation.</description>
    </item>
    
    <item>
      <title>Self Nas Environment Project</title>
      <link>https://wenhan.blog/post/self-nas-environment-project/</link>
      <pubDate>Sun, 05 Apr 2020 15:22:58 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/self-nas-environment-project/</guid>
      <description>This artcle is a note for myself to build a private NAS station using Ubuntu 20.04. The main usage of my NAS is to store photoes. For other services, run webmin to control machine via WebUI, and run Emby/ Jellyfin for multi media. Above 2 will run in docker so I also run portainer to manage them.
Overview Use Samba to share storage, and use PhotoSync to upload photoes from iPhone to NAS.</description>
    </item>
    
    <item>
      <title>Multipass Launch Failed by Network Timeout</title>
      <link>https://wenhan.blog/post/multipass-launch-failed-by-network-timeout/</link>
      <pubDate>Tue, 31 Mar 2020 10:04:31 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/multipass-launch-failed-by-network-timeout/</guid>
      <description>Multipass is a very useful tools to create Ubuntu VM instance. It will provides a CLI to launch and manage the Linux instances. The downloading of a cloud image is also automatically, and a VM can be up and running within minutes.
https://multipass.run/
But in my case, I tried multipass 1.1.0 to quick launch an instance, but it failed with a Network timeout error.
1 2 3 4 5 6  $ multipass version multipass 1.</description>
    </item>
    
    <item>
      <title>Moving From Hexo to Hugo</title>
      <link>https://wenhan.blog/post/moving-from-hexo-to-hugo/</link>
      <pubDate>Mon, 30 Mar 2020 14:07:21 +0900</pubDate>
      
      <guid>https://wenhan.blog/post/moving-from-hexo-to-hugo/</guid>
      <description>HexoからHugoに 今までHexoでブログを書いたが、Golang勉強のついでにHugoに移しました。 理由はいろいろありますが、主な点は以下
 Hexoは複数のモジュールを使うので、たまにインストールがコケる それに対しHugoはバイナリ一つで十分 HTMLファイル生成のスピード、HexoよりHugoが断然に速い  Hugoのインストール方法や利用方法については割愛しましたが、今回のブログ移転で 実際に会った問題を整理する
Tagの付け方 Hexoの場合、以下のタグの付け方が大丈夫でしたが、Hugoの時はだめでした
1  tag: Python   全部以下に統一すれば問題ない
1 2  tags: - Python   Blog mdファイルの保存場所 これはthemeによって異なります。今回はEvenを利用したのでpostになっています。
生成したブログページとGithub Actionの連携 Hexoの場合、deployのサブコマンドでGithubにPush出来ましたが、Hugoの場合はでき ません。Hugo deployコマンドは一応ありますが、AWS,GCE,Azure向けでした。 https://gohugo.io/hosting-and-deployment/hugo-deploy/
そのためファイルを生成して手動でgithub pageのレポジトリーにpushする必要がありま す。生成したブログページのファイルがpublicディレクトリにあります。 Github Actionを利用すれば、新しい記事を書いてpushしたら、上記の処理が全自動に 出来ます。そのやり方は次の記事に纏めます。
httpsの対応 Hugoと関係ないが、ついでにCloudFlareを使ってhttpsへ対応した。</description>
    </item>
    
    <item>
      <title>ASRock Fatal1ty B450 Gaming-ITX &#39;Restore on AC/Power Loss&#39; not working</title>
      <link>https://wenhan.blog/post/asrock-fatal1ty-b450-gaming-itx-restore-on-ac-power-loss-not-working/</link>
      <pubDate>Tue, 01 Oct 2019 13:13:11 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/asrock-fatal1ty-b450-gaming-itx-restore-on-ac-power-loss-not-working/</guid>
      <description>I have a ASRock Fatal1ty B450 Gaming-ITX with the latest BIOS 3.40. As I want to power it on remotely, In Bios setting I enabled &amp;lsquo;Restore on AC/Power Loss&amp;rsquo; option on BIOS, but it&amp;rsquo;s not working.
Then I found below and upgrade my bios firmware to 3.53, and everything works just fine! You can find the v3.53 on below link.
http://forum.asrock.com/forum_posts.asp?TID=12059&amp;amp;title=fatal1ty-b450-gamingitx-restore-on-ac-power-loss</description>
    </item>
    
    <item>
      <title>connect to wifi in Linux via nmcli command</title>
      <link>https://wenhan.blog/post/access-wifi-point-via-command-line-cli/</link>
      <pubDate>Sat, 17 Aug 2019 00:55:53 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/access-wifi-point-via-command-line-cli/</guid>
      <description>I will use nmcli to do this task.
First you need to install network-manager package, and start the Daemon
1 2  $ sudo apt install network-manager $ sudo systemctl start NetworkManager   Then let&amp;rsquo;s check the network interface status by below command
1 2 3 4 5 6 7  $ nmcli dev status DEVICE TYPE STATE CONNECTION wlp2s0 wifi connected xibuka-wifi-5G enp0s31f6 ethernet connected netplan-enp0s31f6 p2p-dev-wlp2s0 wifi-p2p disconnected -- eth0 ethernet unavailable -- lo loopback unmanaged --   Next step is to check the available Wifi access points.</description>
    </item>
    
    <item>
      <title>The begining of bash script</title>
      <link>https://wenhan.blog/post/bash-head-options/</link>
      <pubDate>Tue, 25 Jun 2019 00:12:59 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/bash-head-options/</guid>
      <description>exit script immediately when a command fails
1 2  set -o errexit set -e   output error and exit script immediately when refer to a undefine variable.
1 2  set -o nounset set -u   exit script even a command fails before a pipe
1  set -o pipefail   </description>
    </item>
    
    <item>
      <title>Presentasion about microk8s at containerDaysTokyo</title>
      <link>https://wenhan.blog/post/presentasion-about-microk8s-at-containerdaystokyo/</link>
      <pubDate>Fri, 07 Dec 2018 00:33:49 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/presentasion-about-microk8s-at-containerdaystokyo/</guid>
      <description>I did a presentation about microk8s and snap at ContainerDays Tokyo. The slide(Japanese) can be found as below.
speakerdeck.com
Enjoy!</description>
    </item>
    
    <item>
      <title>OpenStack frequently used command</title>
      <link>https://wenhan.blog/post/openstack-frequently-used-command/</link>
      <pubDate>Thu, 27 Sep 2018 22:09:02 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/openstack-frequently-used-command/</guid>
      <description>OpenStack frequently used command OpenStack Compute - Nova  list instances nova list openstack server list list/check flavor nova flavor-list nova flavor-show &amp;lt;name or ID&amp;gt; openstack flavor list openstack flavor show &amp;lt;name or ID&amp;gt; create flavor openstack flavor create --ram &amp;lt;ram&amp;gt; --vcpus &amp;lt;cpu number&amp;gt; --disk &amp;lt;size&amp;gt; --id &amp;lt;id&amp;gt; &amp;lt;name&amp;gt; nova flavor-create &amp;lt;name&amp;gt; &amp;lt;id&amp;gt; &amp;lt;ram&amp;gt; &amp;lt;disk&amp;gt; &amp;lt;vcpus&amp;gt; launch an instance nova boot &amp;lt;name&amp;gt; --image &amp;lt;image&amp;gt; --flavor &amp;lt;flavor&amp;gt; openstack server create --flavor &amp;lt;flavor&amp;gt; --image &amp;lt;image&amp;gt; &amp;lt;name&amp;gt; launch an instance with network openstack server create --flavor &amp;lt;flavor&amp;gt; --image &amp;lt;image&amp;gt; &amp;lt;name&amp;gt; net-id=&amp;lt;network&amp;gt; launch an instance with key-pair nova boot &amp;lt;name&amp;gt; --image &amp;lt;image&amp;gt; --flavor &amp;lt;flavor&amp;gt; --key-name &amp;lt;key-pair name&amp;gt; openstack server create --flavor &amp;lt;flavor&amp;gt; --image &amp;lt;image&amp;gt; &amp;lt;name&amp;gt; access instance via router ip netns list sudo ip netns exec &amp;lt;qrouter-id&amp;gt; ssh -i &amp;lt;key&amp;gt; user@ip launch an instance with custom port nova boot --image &amp;lt;image&amp;gt; --flavor &amp;lt;flavor&amp;gt; --nic port-id=&amp;lt;port-id&amp;gt; &amp;lt;instance name&amp;gt; delete an instance nova delete &amp;lt;ID&amp;gt; openstack server delete &amp;lt;ID or name&amp;gt;  Openstack Network - Neutron  list network openstack network list list subnetwork openstack subnet list --long create a network openstack network create &amp;lt;net name&amp;gt; create a subnetwork openstack subnet create &amp;lt;subnet name&amp;gt; --network &amp;lt;net name&amp;gt; --subnet-range &amp;lt;ip address&amp;gt;/&amp;lt;prefix&amp;gt; --gateway &amp;lt;gw ip&amp;gt; --allocation-pool start=IP_ADDR,end=IP_ADDR e.</description>
    </item>
    
    <item>
      <title>Certified Kubernetes Administrator (CKA) learning note</title>
      <link>https://wenhan.blog/post/certified-kubernetes-administrator-cka-learning-note/</link>
      <pubDate>Wed, 29 Aug 2018 11:40:56 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/certified-kubernetes-administrator-cka-learning-note/</guid>
      <description>Install  Install docker.io  1  apt install docker.io   If you install docker with other cgroup driver, you have to make sure that docker and Kubernetes will use same cgroup driver.
1 2 3 4 5  cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; /etc/docker/daemon.json { &amp;#34;exec-opts&amp;#34;: [&amp;#34;native.cgroupdriver=systemd&amp;#34;] } EOF    install apt key and source to system  1 2 3 4 5  root@kube-master:~# curl -s https://packages.</description>
    </item>
    
    <item>
      <title>[Juju] Use juju to deploy minecraft server in LXD</title>
      <link>https://wenhan.blog/post/juju-use-juju-to-deploy-minecraft-server-in-lxd/</link>
      <pubDate>Thu, 28 Jun 2018 17:01:36 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/juju-use-juju-to-deploy-minecraft-server-in-lxd/</guid>
      <description>Juju is a deploy tool which supports a very wide range of cloud providers, like AWS, Azure, Google Cloud Platform, MAAS and LXD. This artcle will focus on how to build an OpenStack test environment using Juju and LXD.
installing LXD It is very easy to install LXD, just run below command
1  $ sudo apt-install lxd   If you can&amp;rsquo;t find lxd package, run below command to add PPA(Personal Package Archive) to find LXD package.</description>
    </item>
    
    <item>
      <title>Suspend issue on Thinkpad X1C 6th with Ubuntu 18.04</title>
      <link>https://wenhan.blog/post/suspend-issue-on-thinkpad-x1c-6th-with-ubuntu-18-04/</link>
      <pubDate>Mon, 11 Jun 2018 15:38:10 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/suspend-issue-on-thinkpad-x1c-6th-with-ubuntu-18-04/</guid>
      <description>S3 Suspend not supported by default There is an issue about suspend on Thinkpad X1 Carbon when using Ubuntu 18.04. When you close the lid suspend does not works well. It will continue cose some power and get you laptop hot.
The root cause is the 6th gen X1 Carbon supports S0i3(Which is also known as Windows Modern Standby) but does not support the S3 sleep state.
S0i3 sleep support After some researching, the workaround can be this:</description>
    </item>
    
    <item>
      <title>Error: Failed container creation: Failed to load raw.lxc</title>
      <link>https://wenhan.blog/post/error-failed-container-creation-failed-to-load-raw-lxc/</link>
      <pubDate>Mon, 04 Jun 2018 16:19:39 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/error-failed-container-creation-failed-to-load-raw-lxc/</guid>
      <description>I follow below URL to try to install and test MaaS,
https://docs.maas.io/2.1/en/installconfig-lxd-install
At the profile edit part, from above documents
 lxc profile edit maas replace the {} after config with the following (excluding config:): 1 2 3 4 5 6  config: raw.lxc: |- lxc.cgroup.devices.allow = c 10:237 rwm lxc.aa_profile = unconfined lxc.cgroup.devices.allow = b 7:* rwm security.privileged: &amp;#34;true&amp;#34;    At the launch step, I hit below issue, 1 2 3  $ lxc launch -p maas ubuntu:16.</description>
    </item>
    
    <item>
      <title>Ansible 入門 - 基本操作(チュートリアル)</title>
      <link>https://wenhan.blog/post/getting-started-with-ansible-jp-basic/</link>
      <pubDate>Mon, 09 Apr 2018 15:25:32 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/getting-started-with-ansible-jp-basic/</guid>
      <description>こちらの記事はではAnsibleを紹介するための文章で、元Red Hat社員のJingjing Shiが作成し、Wenhan Shiが日本語に翻訳しました。内容の校正はHideki SaitoとKento Yagisawaが協力しています。Ansibleの基礎知識から、実際の現場で利用できる実運用まで紹介しています。
本文内にあるすべてのansible playbookの例は、以下のgithubのURLから利用できる。 https://github.com/ansible-book/ansible-first-book-examples もし不備やコメントがありましたら、作者shijingjing02@163.comまたは翻訳者shibunkan@gmail.com に連絡してください。
詳細の内容を下記三つに分けて説明します。
Ansible 入門 - 紹介 Ansible 入門 - 基本 Ansible 入門 - 応用
本章では、簡単な例を使ってAnsibleの基本的な使い方を説明する。
 インストール 管理対象のサーバー（サーバリストの管理） コマンドラインによるサーバー管理(Ad-hoc command) スクリプトによるサーバー管理(スクリプト言語 Playbook) モジュール  インストール ここでは Red Hat 系 Linux でのインストールを前提に解説にする。他のOSに関していAnsibleのWebページをご参照ください。
管理者ノード Ansible パッケージをインストール 1 2 3 4  # Redhat/CentOS Linuxの場合, epolリポジトリをインストールする必要がある。 # Fedoraの場合、デフォルトのリポジトリにAnsibleを含まれているため，直接インストールできる sudo yum install epel-release sudo yum install ansible -y   管理者ノードからリモートノードの接続設定 SSH keyによる認証パスワードレス）方式を設定する。
1 2 3 4 5 6  # ssh key を生成 ssh-keygen # リモートノードにssh keyをコピー ssh-copy-id remoteuser@remoteserver # リモートノードをknows_hostsに追加（ssh Keyの保存確認がなくなる） ssh-keyscan remote_servers &amp;gt;&amp;gt; ~/.</description>
    </item>
    
    <item>
      <title>Ansible 入門 - 応用</title>
      <link>https://wenhan.blog/post/getting-started-with-ansible-jp-adv/</link>
      <pubDate>Mon, 09 Apr 2018 15:20:32 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/getting-started-with-ansible-jp-adv/</guid>
      <description>こちらの記事はではAnsibleを紹介するための文章で、元Red Hat社員のJingjing Shiが作成し、Wenhan Shiが日本語に翻訳しました。内容の校正はHideki SaitoとKento Yagisawaが協力しています。Ansibleの基礎知識から、実際の現場で利用できる実運用まで紹介しています。
本文内にあるすべてのansible playbookの例は、以下のgithubのURLから利用できる。 https://github.com/ansible-book/ansible-first-book-examples もし不備やコメントがありましたら、作者shijingjing02@163.comまたは翻訳者shibunkan@gmail.com に連絡してください。
詳細の内容を下記三つに分けて説明します。
Ansible 入門 - 紹介 Ansible 入門 - 基本 Ansible 入門 - 応用
本章では、もっと自由に運用するために、Ansibleの高度な使い方を説明する。
 Ansibleの設定ファイル サーバーリスト管理（Host Inventory） Playbookの上級な書き方 Extraモジュールの利用  Ansible設定ファイル 設定内容  基本の設定内容     項目 詳細 内容（デフォルト）     inventory リモートノードリスト管理ファイル /etc/ansible/hosts   library 拡張モジュールフォルダ /usr/share/my_modules/   remote_tmp リモートノード上のファイル一時保存場所 $HOME/.ansible/tmp   local_tmp 管理者ノード上のファイル一時保存場所 $HOME/.ansible/tmp     高度の設定内容     項目 詳細 内容（デフォルト）     accelerate_port 接続ポート番号 5099   accelerate_timeout タイムアウト 30   accelerate_connect_timeout 接続タイムアウト 5    上記は設定できる内容の一部しかすぎない。以下のAnsible設定ファイルの全体を通して、どんなことができるのはは理解できる</description>
    </item>
    
    <item>
      <title>Ansible 入門 - 紹介</title>
      <link>https://wenhan.blog/post/getting-started-with-ansible-jp-intro/</link>
      <pubDate>Mon, 09 Apr 2018 15:15:32 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/getting-started-with-ansible-jp-intro/</guid>
      <description>こちらの記事はではAnsibleを紹介するための文章で、元Red Hat社員のJingjing Shiが作成し、Wenhan Shiが日本語に翻訳しました。内容の校正はHideki SaitoとKento Yagisawaが協力しています。Ansibleの基礎知識から、実際の現場で利用できる実運用まで紹介しています。
本文内にあるすべてのansible playbookの例は、以下のgithubのURLから利用できる。 https://github.com/ansible-book/ansible-first-book-examples もし不備やコメントがありましたら、作者shijingjing02@163.comまたは翻訳者shibunkan@gmail.com に連絡してください。
詳細の内容を下記三つに分けて説明します。
Ansible 入門 - 紹介 Ansible 入門 - 基本 Ansible 入門 - 応用
本章では、Ansibleの基礎部分の紹介を説明する。
Ansibleとは Ansibleとはなにか？ Ansibleは、複数のサーバを一括でコントロールする構成管理ツールである。コントロールできるサーバ対象はリモートの仮想マシンでも物理マシンでも問ローカルのサーバマシンも問題ない。
Ansibleでなにができる？ Ansibleでは、SSHなどを利用し管理ノードからリモートノードへの通信を行う。理論上では、サーバ管理者がsshでサーバにログインした後できるすべてのことに対し、Ansibleも同じことができる。
例えば
 ファイルコピー パッケージインストール デーモンサービス起動 その他  アーキテクチャ 管理者ノードとリモートノードの間では、SSHプロトコルを利用して通信を行っている。そのため、Ansible環境を設定する時に、管理者ノードからリモートノードへSSHログインできることが必要である。ただし、SSHログインはパスワードレスに設定しなければいけない。詳細な設定方法は後ほど説明する。
SSH接続 管理者ノードでAnsibleをインストールし、スクリプトの編集を行う。管理者ノードでAnsibleのコマンドやスクリプトを実行する時に、管理対象のサーバにSSHで接続する。管理対象のサーバの上にパッケージをインストールする必要がない。 多種類のサーバに対応 AnsibleはRedHat系、Debian系のLinuxと、Windows系のサーバを同時に管理することができる。管理者ノードはスクリプトを実行する時のみリモートサーバに接続するため、他の同期処理がない。そのため、通常の状態では、停電などの異常状態はAnsibleを影響しない。 Ansible Towerのアーキテクチャ なぜAnsible Towerが必要なのか？ Ansible Towerは企業向けの有償ソフトウェアである。 前章のAnsible アーキテクチャとこれからのAnsibleのインストールでは、すべてのAnsibleでの管理対象となるサーバは、sshの公開鍵認証によるパスワードレスSSH接続を設定する必要がある。一般ユーザの場合、数台の仮想サーバやリモートサーバのみを管理するため特に問題ないが、企業ユーザに対し業務プロセスと安全性を確保しにくくなる。
 1台のリモートサーバを追加する毎に、パスワードレスなSSH接続の設定を手動で行うことは非常に非効率的である。企業レベルのサーバが数百台、数千台規模になると、各サーバ管理者が自分の管理者ノードで全サーバに対しパスワードレスSSH接続の設定が必要となり、作業量は膨大になる。 管理者がパスワードレスSSH接続の為のssh keyを入手したり、他人にコピーしたりすると、本番環境に対し重大なセキュリティの問題になる。  Ansible Towerでなにができるのか？ Ansible Towerは企業ユーザ向けに開発されている、集中管理や権限による制限、ジョブスケジューリング機能などを提供するソフトウェアである。このソフトウェアは管理者にWebUIやREST APIを提供し、Playbookの実行やワークフローテンプレートによる条件分岐などをサポートする。
 管理者は、Ansible Tower上にサーバのssh keyを使用したりシェアしたりすることができるが、ssh keyの内容参照やコピーすることはできない。 Ansible Towerでは、各管理者がシェアしているplaybookスクリプトを参照するとこができるため、重複する作業を減らすことができる。 また、Ansible Towerは現在すべてのサーバでのplaybookの実行状況を集計/表示するため、状態の確認や統計もできる。  下記の図でAnsible Towerのアーキテクチャを示している。</description>
    </item>
    
    <item>
      <title>The difference between server-side healing and client-side healing in GlusterFS</title>
      <link>https://wenhan.blog/post/the-different-between-server-side-heal-and-client-side-heal-in-glusterfs/</link>
      <pubDate>Mon, 26 Mar 2018 09:56:21 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/the-different-between-server-side-heal-and-client-side-heal-in-glusterfs/</guid>
      <description>There are 2 kinds of healing functions in GlusterFS, server-side heal and client-side heal.
Server side heal is automatically executed by self-heal daemon on all gluster server nodes. It does healing by crawling file/directory information from .glusterfs directory on brick path. So it will keep the file-data and meta-data to be consistent from server side.
Client side heal is different, it will triggers heal for the particular file whenever client accesses files from mount path, which means a file operation on file descriptor.</description>
    </item>
    
    <item>
      <title>failed at yum update and how to fix it</title>
      <link>https://wenhan.blog/post/failed-at-yum-update-and-how-to-fix-it/</link>
      <pubDate>Sun, 18 Feb 2018 16:46:33 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/failed-at-yum-update-and-how-to-fix-it/</guid>
      <description>I hit an error when running yum update on my centOS 7, the command failed to update my OS!
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # yum update Loaded plugins: fastestmirror Determining fastest mirrors * base: centos.gbeservers.com * epel: linux.mirrors.es.net * extras: linux.mirrors.es.net * ius: hkg.</description>
    </item>
    
    <item>
      <title>Docker basic foundation</title>
      <link>https://wenhan.blog/post/docker-basic-foundation/</link>
      <pubDate>Sun, 18 Feb 2018 16:35:32 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/docker-basic-foundation/</guid>
      <description>Base on CentOS 7, Docker 1.12.6
Install Docker Some pre-requirment to install Docker to a Linux OS.
 Docker only can be installed on a 64 bit OS. Kernel version over 3.10 is recommended. recommend Need to enable cgroup and namespace.  Now it is easier to install Docker in CentOS or Fedora, it can be searched by yum command like below:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # yum search docker | grep ^docker docker-client.</description>
    </item>
    
    <item>
      <title>How to disable IPv6 inside a container/pod in OpenShift</title>
      <link>https://wenhan.blog/post/how-to-disable-ipv6-inside-a-container-pod-in-openshift/</link>
      <pubDate>Thu, 01 Feb 2018 15:46:56 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-disable-ipv6-inside-a-container-pod-in-openshift/</guid>
      <description>Although the container/pod in OpenShift transfer data by IPv4 protocol, and you do not need to worry about the setting of IPv6. But in some case people want to disable IPv6 inside the container without effecting other container/pods or host OS.
Here is an example of the IPv6 info outputed from a container.
1 2 3 4 5 6 7 8 9 10 11 12 13  [root@ocp37 ~]# oc exec django-ex-4-6gmsj -- ip a 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.</description>
    </item>
    
    <item>
      <title>Gluster filename and GFID interconversion</title>
      <link>https://wenhan.blog/post/gluster-filename-and-gfid/</link>
      <pubDate>Mon, 11 Dec 2017 15:41:23 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/gluster-filename-and-gfid/</guid>
      <description>create test file Mount gluster volume and create a file
1 2 3 4  [root@client-1 ~]# mount -t glusterfs gluster-node-1:/vol /mnt [root@client-1 ~]# mkdir -p /mnt/hoge/hello-gluster/ [root@client-1 ~]# touch /mnt/hoge/hello-gluster/file [root@client-1 ~]# umount /mnt/   Get GFID of a file in Gluster volume From brick directory Login to gluster node and locate file in brick directory.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [root@gluster-node-1 ~]# gluster volume info vol Volume Name: vol Type: Replicate Volume ID: 4ac36bcc-7127-48c4-ac21-421850d8bc47 Status: Started Snapshot Count: 0 Number of Bricks: 1 x 3 = 3 Transport-type: tcp,rdma Bricks: Brick1: gluster-node-1:/gluster/brick-vol &amp;lt;-- confirm the brick path Brick2: gluster-node-2:/gluster/brick-vol Brick3: gluster-node-3:/gluster/brick-vol Options Reconfigured: performance.</description>
    </item>
    
    <item>
      <title>AWK - time functions</title>
      <link>https://wenhan.blog/post/awk-time-functions/</link>
      <pubDate>Fri, 24 Nov 2017 08:34:34 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/awk-time-functions/</guid>
      <description>Apart of date, awk also has below built-in time functions which will help you to resolve time convert problem
systime() This will return the current time as the number of seconds since the Epoch (1970-01-01 00:00:00).
1 2 3 4  $ awk &amp;#39;BEGIN { &amp;gt; print &amp;#34;Number of seconds since the Epoch = &amp;#34; systime() &amp;gt; }&amp;#39; Number of seconds since the Epoch = 1511480989   mktime(YYYY MM DD HH MM SS) This will convert date string &amp;ldquo;YYYY MM DD HH MM SS&amp;rdquo; to the number of seconds since the Epoch.</description>
    </item>
    
    <item>
      <title>How to check if a disk is SSD or HDD</title>
      <link>https://wenhan.blog/post/how-to-check-if-a-disk-is-ssd-or-hdd/</link>
      <pubDate>Thu, 02 Nov 2017 08:27:14 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-check-if-a-disk-is-ssd-or-hdd/</guid>
      <description>Linux will detects SSD automatically. Since kernel version 2.6.29, you can check /dev/sda with following command
1  # cat /sys/block/sda/queue/rotational   The return number 0 shows you /dev/sda is a SSD, and 1 shows it is a HDD. Note that this command may not work when your disk is created by hardware RAID.
Another way is to use lsblk command, a part of the util-linux package.
1 2 3 4  # lsblk -d -o name,rota NAME ROTA sda 0 sdb 1   ROTA means rotational device, 1 for true, 0 for false.</description>
    </item>
    
    <item>
      <title>How to sort ps command output</title>
      <link>https://wenhan.blog/post/how-to-sort-ps-command-output/</link>
      <pubDate>Tue, 19 Sep 2017 14:11:37 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-sort-ps-command-output/</guid>
      <description>ps command has a --sort option which can help you to sort processes.
1 2 3 4 5 6 7  --sort spec Specify sorting order. Sorting syntax is [+|-]key[,[+|-]key[,...]]. Choose a multi-letter key from the STANDARD FORMAT SPECIFIERS section. The &amp;#34;+&amp;#34; is optional since default direction is increasing numerical or lexicographic order. Identical to k. For example: ps jax --sort=uid,-ppid, +pid   Sort ps output by memory From high to low The highest is at the top of the command</description>
    </item>
    
    <item>
      <title>Beginner guide of systemd on CentOS7/RHEL7</title>
      <link>https://wenhan.blog/post/beginner-guide-of-systemd-on-centos7-rhel7/</link>
      <pubDate>Mon, 11 Sep 2017 10:19:16 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/beginner-guide-of-systemd-on-centos7-rhel7/</guid>
      <description>Introduction of systemd Before CentOS 7 and RHEL 7, System V was used to be the system controller. The system controller can manage all processes, services, and start task. System V has a performance problem as it is using script to manage the tasks. So it can only start the task serially, which will slow down the startup of the system.
From CentOS 7, the systemd become the new system controller.</description>
    </item>
    
    <item>
      <title>systemctl command return &#39;Failed to connect to bus: No such file or directory&#39; in a docker container</title>
      <link>https://wenhan.blog/post/systemctl-command-return-failed-to-connect-to-bus-no-such-file-or-directory-in-a-docker-container/</link>
      <pubDate>Tue, 05 Sep 2017 10:30:55 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/systemctl-command-return-failed-to-connect-to-bus-no-such-file-or-directory-in-a-docker-container/</guid>
      <description>To enable and start a cron job and a httpd server in a docker container, I tried systemctl command but get an error output like this
1 2 3 4  [root@5f1f0a5cde43 app]# systemctl status crond Failed to connect to bus: No such file or directory [root@5f1f0a5cde43 app]# systemctl status httpd Failed to connect to bus: No such file or directory   Fix this issue by add --privileged parameter to docker run  command</description>
    </item>
    
    <item>
      <title>How to change timezone in CentOS 7 or RHEL 7</title>
      <link>https://wenhan.blog/post/how-to-change-timezone-in-centos-7-or-rhel-7/</link>
      <pubDate>Thu, 10 Aug 2017 14:18:08 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-change-timezone-in-centos-7-or-rhel-7/</guid>
      <description>check the current timezone status 1 2 3 4 5 6 7 8 9  [root@rhel7 ~]# timedatectl Local time: Thu 2017-08-10 05:19:53 UTC Universal time: Thu 2017-08-10 05:19:53 UTC RTC time: Thu 2017-08-10 05:19:52 Time zone: UTC (UTC, +0000) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a   list the avaliable timezones 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@rhel7 ~]# timedatectl list-timezones Asia/Aden Asia/Almaty Asia/Amman Asia/Anadyr Asia/Aqtau Asia/Aqtobe Asia/Ashgabat .</description>
    </item>
    
    <item>
      <title>Desktop Notifier by Python</title>
      <link>https://wenhan.blog/post/desktop-notifier-by-python/</link>
      <pubDate>Fri, 28 Jul 2017 16:37:40 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/desktop-notifier-by-python/</guid>
      <description>This article show how to send desktop notice using Python
Install requirments we need to install notify2 by pip
1 2 3 4 5  # pip install notify2 Collecting notify2 Downloading notify2-0.3.1-py2.py3-none-any.whl Installing collected packages: notify2 Successfully installed notify2-0.3.1   Coding First we need to import notify2
1  import notify2   Then need to initialise the d-bus connection. D-Bus is a message bus system, a simple way for applications to talk to one another.</description>
    </item>
    
    <item>
      <title>Install Chrome Browser via yum in CentOS or Fedora or RHEL</title>
      <link>https://wenhan.blog/post/install-chrome-browser-via-yum-in-centos-or-fedora-or-rhel/</link>
      <pubDate>Fri, 14 Jul 2017 09:29:58 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/install-chrome-browser-via-yum-in-centos-or-fedora-or-rhel/</guid>
      <description>Create a google yum repository Create a file /etc/yum.repos.d/google-chrome.repo and add the following into it.
1 2 3 4 5 6  [google-chrome] name=google-chrome baseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearch enabled=1 gpgcheck=1 gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub   Check the google repository Run following command to check the repository is available.
1  # yum info google-chrome-stable   From the output you should find the lastest version of the package google-chrome-stable
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # yum info google-chrome-stable Fedora 26 - x86_64 - Updates 6.</description>
    </item>
    
    <item>
      <title>OpenShift Configure authentication and User Agent using HTPasswd</title>
      <link>https://wenhan.blog/post/openshift-configure-authetication-and-user-agent-using-htpasswd/</link>
      <pubDate>Wed, 12 Jul 2017 14:43:47 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/openshift-configure-authetication-and-user-agent-using-htpasswd/</guid>
      <description>As we Install the OpenShift by Ansible method, identity provider is set to Deny all by default, which will deny access from all users. To allow access for users, you must choose another identity provider and configure the master configuration file. By default, the master configuration file is located at /etc/origin/master/master-config.yaml. OpenShift has several identity providers which can help you to manager user authentication. I will use HTPasswd this time. You can find more information in Configuring Authentication and User Agent</description>
    </item>
    
    <item>
      <title>[OpenShift]Quick install OpenShift to multi nodes</title>
      <link>https://wenhan.blog/post/openshift-use-ansible-to-install-openshift-to-multi-nodes/</link>
      <pubDate>Fri, 07 Jul 2017 15:32:15 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/openshift-use-ansible-to-install-openshift-to-multi-nodes/</guid>
      <description>In this article we will show you how to install OpenShift in mutliple nodes using a quick install command, atomic-openshift-installer, which is powered by ansible.
Host preparation I use under virtual machines for OpenShift nodes to deploy
   Type CPU Mem HDD hostname OS     Master 1 2 GB 20 GB master.example.com RHEL 7   node 1 2 GB 20 GB node1.example.com RHEL 7   node 1 2 GB 20 GB node2.</description>
    </item>
    
    <item>
      <title>How to copy text to the system clipboard in VIM</title>
      <link>https://wenhan.blog/post/how-to-copy-paste-text-to-from-the-system-clipboard-in-vim/</link>
      <pubDate>Tue, 04 Jul 2017 11:44:42 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-copy-paste-text-to-from-the-system-clipboard-in-vim/</guid>
      <description>Make sure your VIM have +clipboard enabled, Add &amp;ldquo;set clipboard=unnamedplus&amp;rdquo; to .vimrc  check +clipboard is enabled 1 2 3  # vim --version | grep clipboard +clipboard +job +path_extra +user_commands +eval +mouse_dec +statusline +xterm_clipboard   If it shows &amp;lsquo;-clipboard&amp;rsquo;, you need to compile VIM with this feature.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  $ git clone https://github.</description>
    </item>
    
    <item>
      <title>How to keep process running after log off</title>
      <link>https://wenhan.blog/post/how-to-keep-process-script-running-after-end-the-ssh-session/</link>
      <pubDate>Thu, 29 Jun 2017 14:31:14 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-keep-process-script-running-after-end-the-ssh-session/</guid>
      <description>tmux is an opensource software that can help you to do this. There are a lot of other things tmux can do, but now let me explain how to keep process running even end the ssh session. Please follow the steps:
 start a tmux session by input tmux to the shell. start your process or script inside the tmux session. leave(detach) the tmux session by input Ctrl+b and then d.</description>
    </item>
    
    <item>
      <title>[VIM] Use built in Spell Check</title>
      <link>https://wenhan.blog/post/vim-use-built-in-spell-check/</link>
      <pubDate>Mon, 26 Jun 2017 16:37:57 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/vim-use-built-in-spell-check/</guid>
      <description>From version 7, VIM has a built in spell check function, but disable by default.
Enable/Disable You can use :set spell  and  :set nospell to enable and disable it. The spell check isn&amp;rsquo;t only for English, use :echo &amp;amp;spelllang to confirm the current target langurage. Use:set spelllang=en_GB.UTF-8 to change the target langurage, also you can use set spelllang=en_us,nl,medical to set it to multiple langurage.
Spell check Use ]s to move to the next, [s to move to the previous spell mistake.</description>
    </item>
    
    <item>
      <title>[OpenShift]Install OpenShift and Create first project Hello-OpenShift</title>
      <link>https://wenhan.blog/post/openshift-install-openshift-and-create-first-project-hello-openshift/</link>
      <pubDate>Mon, 26 Jun 2017 13:40:40 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/openshift-install-openshift-and-create-first-project-hello-openshift/</guid>
      <description>Install Linux OS and confirm network setting. You need to create a Linux OS machine to install OpenShift. The minimum requirement is
   CPU Memory hard disk Network     x86_64 1 core 2 GB 20 GB IPv4    First you need to install CentOS 7.3, by select minimum setup. After you finish the installation, check your IP address to make sure you have available IP to use.</description>
    </item>
    
    <item>
      <title>How to clear memory cache, buffer and swap on linux</title>
      <link>https://wenhan.blog/post/how-to-clear-memory-cache-buffer-and-swap-on-linux/</link>
      <pubDate>Fri, 16 Jun 2017 12:05:35 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/how-to-clear-memory-cache-buffer-and-swap-on-linux/</guid>
      <description>How to clear cache in Linux  Clear PageCache only  1  # sync ; echo 1 &amp;gt; /proc/sys/vm/drop_caches    Clear Dentries and inodes(metadata)  1  # sync ; echo 2 &amp;gt; /proc/sys/vm/drop_caches    Clear All cache(include PageCache and Dentries and inode)  1  # sync ; echo 3 &amp;gt; /proc/sys/vm/drop_caches   How to clear swap space in Linux 1  # swapoff -a &amp;amp;&amp;amp; swapon -a   NOTE: This may make your system unstable when you have low RAM already.</description>
    </item>
    
    <item>
      <title>GlusterFS Failed to probe a cloned peer</title>
      <link>https://wenhan.blog/post/glusterfs-failed-to-probe-a-cloned-peer/</link>
      <pubDate>Thu, 15 Jun 2017 11:43:46 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/glusterfs-failed-to-probe-a-cloned-peer/</guid>
      <description>If you want to save some time for setup each gluster system, you can just setup all the necessary configuration in one vm, and then cloning it. But you may in trouble for probe a peer from another node. When you try to run the command, you could get the following error messages:
1 2  [root@node1 ~]# gluster peer probe node2 peer probe: failed: Peer uuid (host node2) is same as local uuid   this is because when glusterfs-server package is first installed, a node UUID file will be created at /var/lib/glusterd/glusterd.</description>
    </item>
    
    <item>
      <title>Linux文件的特殊权限设置 setuid setgit sticky</title>
      <link>https://wenhan.blog/post/linux-special-permissions-for-file-and-dir-cn/</link>
      <pubDate>Wed, 03 May 2017 01:17:17 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/linux-special-permissions-for-file-and-dir-cn/</guid>
      <description>特殊权限对文件和文件夹的影响 Linux系统中存在三个比较特殊的权限，分别是setuid，setgid，和sticky。 下面的表显示了他们之间的区别和对文件及文件夹的影响。
   权限种类 对文件的影响 对文件夹的影响。     u+s(suid) 文件在自己的owner权限下执行，而并不是在执行这个文件的用户下执行。好处就是不管谁执行这个文件，环境变数等常量都可以统一为onwer的 无影响   g+s(sgid) 跟setuid很像，文件执行时会在自己的group下执行。 文件夹内新文件的group都会跟上层文件夹的group一致   o+t(sticky) 无影响 对文件夹有w权限的用户，仅允许更改和删除属于自己的文件。也就是owner是自己的文件。对其他用户的文件无法更改或删除。    特殊权限的设定。 用记号设定: setuid = u+s; setgid = g+s; sticky = o+t 用数字设定: setuid = 4; setgid = 2; sticky = 1
例
1 2  # chmod g+s file # chmod 1755 file   </description>
    </item>
    
    <item>
      <title>ファイルとディレクトリへの特殊パーミッション</title>
      <link>https://wenhan.blog/post/linux-special-permissions-for-file-and-dir-jp/</link>
      <pubDate>Thu, 27 Apr 2017 23:59:20 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/linux-special-permissions-for-file-and-dir-jp/</guid>
      <description>特殊パーミションの説明 ファイルとフォルダに対し、setuid、setgid、sticky bitの三つの特殊パーミッションが存在する。 setuidとsetgidパーミッションは、コマンドを実行したユーザまたはグループではなく、ファイルの所有者として実行したことを意味する。 sticky bitパーミッションは、ファイルの削除に関する特殊な制限があり、ファイルの所有者及びrootのみがディレクトリ内のファイルを削除できるようになっている。
   特殊パーミッション ファイルへの影響 フォルダへの影響     u+s(suid) ファイルを実行したユーザではなく、ファイルの所有者としてファイルが実行される。 影響なし   g+s(sgid) ファイルが所属するグループとして実行される。 フォルダ内に新規作成したファイルの所有グループは、フォルダの所有グループと同じになる。   o+t(sticky) 影響なし フォルダに書き込みパーミションを持つユーザは、自分が所有しているファイルのみ削除できる。他のユーザが所有するファイルの削除または編集はできない。    特殊パーミションの設定 記号を使用: setuid = u+s; setgid = g+s; sticky = o+t 数字を使用: setuid = 4; setgid = 2; sticky = 1
例
1 2  # chmod g+s file // fileに対してsetgidビットを追加 # chmod 1755 file // fileに対してstickyビットを追加   </description>
    </item>
    
    <item>
      <title>Linux ユーザパスワードの有効期限の管理</title>
      <link>https://wenhan.blog/post/linux-password-aging-jp/</link>
      <pubDate>Thu, 27 Apr 2017 23:15:00 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/linux-password-aging-jp/</guid>
      <description>Linuxのユーザパスワードの有効期限(aging)の管理について説明する。
 last chage (-d) : パスワードが最後に変更した日数 min days (-m) : パスワードが変更可能の最小日数 max days (-M) : パスワードの変更が必要となる最大日数 warn days (-W) : パスワードの有効期限が近づき、変更を促す（ワーニング）の日数 password expiration date : パスワード有効期限 inactive days (-l) : パスワードの有効期限が切れた後に、アカウントが保持される日数 inactive date : アカウントが非アクティブになる期限  上記情報の変更は、chage コマンドで実現できる。
1  # chage -m 0 -M 60 -W 7 -l 30   また、chage コマンドに対し以下の使い方もある。
 次回ログイン時に強制パスワードを変更させる  1  # chage -d 0 username    現在の設定一覧を表示  1  # chage -l username    指定した日付でアカウントが期限切れになる  1  # chage -E YYYY-MM-DD username   ユーザアカウントに関連する内容で他にも</description>
    </item>
    
    <item>
      <title>ソフトリンクとハードリンクの違い</title>
      <link>https://wenhan.blog/post/soft-link-and-hard-link-ja/</link>
      <pubDate>Thu, 27 Apr 2017 22:14:48 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/soft-link-and-hard-link-ja/</guid>
      <description>ソフトリンクとハードリンクの違いについてメモする 他にも思い出したらまた追記する。
   項目 ソフトリンク ハードリンク     size 4 byte 表示上元ファイルと同じ   inode 元ファイルと異なるinodeを持つ 元ファイルと同じinodeを持つ   制限 - 元ファイルと同じファイルシステム上にある必要がある    以下でリンクのサイズとinode番号の違いがわかるはず。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  wenhanMBP: /tmp/link → ls -li total 1024 12807105 -rw-r--r-- 1 shiwenhan wheel 524288 4 27 22:18 file wenhanMBP: /tmp/link → ln file hardlink-to-file wenhanMBP: /tmp/link → ls -li total 2048 12807105 -rw-r--r-- 2 shiwenhan wheel 524288 4 27 22:18 file 12807105 -rw-r--r-- 2 shiwenhan wheel 524288 4 27 22:18 hardlink-to-file wenhanMBP: /tmp/link → ln -s file softlink-to-file wenhanMBP: /tmp/link → ls -lih total 2056 12807105 -rw-r--r-- 2 shiwenhan wheel 512K 4 27 22:18 file 12807105 -rw-r--r-- 2 shiwenhan wheel 512K 4 27 22:18 hardlink-to-file 12807448 lrwxr-xr-x 1 shiwenhan wheel 4B 4 27 22:27 softlink-to-file -&amp;gt; file   </description>
    </item>
    
    <item>
      <title>fix hexo error output &#39;./build/Release/DTraceProviderBindings&#39;</title>
      <link>https://wenhan.blog/post/fix-hexo-error-output-build-release-dtraceproviderbindings/</link>
      <pubDate>Fri, 21 Apr 2017 00:56:19 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/fix-hexo-error-output-build-release-dtraceproviderbindings/</guid>
      <description>There is a noisy error message appears each time when I run hexo command
1  Error: Cannot find module &amp;#39;./build/Release/DTraceProviderBindings&amp;#39;   It is just a trace error and doesn&amp;rsquo;t stop my work, but , it was so NOISY and I realy want to remove it.
From the follow links, https://github.com/hexojs/hexo/issues/1922 https://github.com/yarnpkg/yarn/issues/1915
I know the root cause is because the dtrace-provider package. And I don&amp;rsquo;t use is at all, so I just want to uninstall it.</description>
    </item>
    
    <item>
      <title>Python每日获取天气情报并通过邮件通知</title>
      <link>https://wenhan.blog/post/get-weather-info-and-send-by-gmail-python/</link>
      <pubDate>Fri, 21 Apr 2017 00:16:17 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/get-weather-info-and-send-by-gmail-python/</guid>
      <description>因为没看天气预报，被大雨浇了几次之后，我打算为我这样的懒人写一个小程序。 很简单，算是Python的一个小练习，用Python实现一个邮件提醒每日天气。
这段程序一共分两步
 通过网站获取天气信息 将天气信息通过邮件发送到指定信箱  获取天气信息 这里我用了常用的requests和BeautifulSoup4来获取网页并抽取信息。 网站用tenki.jp搜索天气，然后通过id来抽取搜索界面的天气信息框框。 搜索界面如下，可以看到用BS4抽取id为&amp;rsquo;map_world_point_wrap&amp;rsquo;的以下的HTML就好了。 我们准备直接发送HTML代码，这样看起来更好看一些。
代码如下 注：soup.find之后需要将内容转换为string格式，不然python2环境下无法发送邮件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  #!/root/.pyenv/shims/python #-*- coding: UTF-8 -*- import sys import time import requests from bs4 import BeautifulSoup #Some User Agents hds=[{&amp;#39;User-Agent&amp;#39;:&amp;#39;Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.</description>
    </item>
    
    <item>
      <title>Install vim 8 with python support on mac</title>
      <link>https://wenhan.blog/post/install-vim-8-with-python/</link>
      <pubDate>Sat, 15 Apr 2017 00:50:08 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/install-vim-8-with-python/</guid>
      <description>Today I configure my development envirment for my mac pro. And I find it is much easier to install VIM 8 with python support use brew. (much more easier than cent 7)
If you have brew, you just need to run
1  brew install --with-python vim   If you want both python3 and python2 support, just run this
1  brew install --with-python --with-python3 vim   Update: you may need to use below command on some latest OS for python2</description>
    </item>
    
    <item>
      <title>cannot ssh to server as root</title>
      <link>https://wenhan.blog/post/cannot-ssh-to-server-by-root-user/</link>
      <pubDate>Thu, 16 Feb 2017 16:36:12 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/cannot-ssh-to-server-by-root-user/</guid>
      <description>rootパスワードを知っているのに、rootでssh接続できない問題の解決方法です。
実はsshdの設定ファイルに、rootでのログイン許可を設定するパラメータがあります。 Linux環境では、設定ファイル/etc/ssh/sshd_configに対し
1  PermitRootLogin no   を
1  PermitRootLogin yes   に変更し、sshdを再起動すれば、アクセス出来るようになる。
1  # systemctl restart sshd   また、以下のように自動ログインをOFFにするパラメータも存在する
1  PubkeyAuthentication no   特定のIPに対しての個別設定も可能
1 2  Match Address 172.25.0.11 PubkeyAuthentication no   </description>
    </item>
    
    <item>
      <title>Pythonでスパイダーを作る</title>
      <link>https://wenhan.blog/post/crawling-webpage-use-python-requests/</link>
      <pubDate>Thu, 01 Dec 2016 00:54:09 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/crawling-webpage-use-python-requests/</guid>
      <description>PythonのRequestsライブラリを利用してウェブページの内容を抽出し保存する。 そして、BeautifulSoupライブラリを利用し、欲しい情報を抽出する。
Requestsとは RequestsはPythonのHTTPライブラリで、urllib2より断然使いやすい。 公式サイトに、
 Requests is an Apache2 Licensed HTTP library, written in Python, for human beings.
 の説明の通り、人間によって読みやすくコーディングできる。
Beautifulsoupとは BeautifulSoupはPythonで動作するHTMLとXMLのパーサーです。
インストール 1 2  pip install requests pip install BeautifulSoup   使い方 1 2  import requests from bs4 import BeautifulSoup   requestsライブラリでは、各種のHTTPメソッドに１対１のメソッドがあります。
1 2 3 4 5  requests.get(&amp;#39;URL&amp;#39;) requests.post(&amp;#39;URL&amp;#39;) requests.put(&amp;#39;URL&amp;#39;) requests.delete(&amp;#39;URL&amp;#39;) requests.head(&amp;#39;URL&amp;#39;)   初めてのスパイダー アマゾンの本のランキングの内容を取ってみよう。以下のことを要件とする。
 ブラウザがアクセスしているように、ヘッダ情報を編集する。 ページの取得が成功の場合のみ、ページ内容をファイルに保存する。 売れ筋ランキングの1-20位の本の順位とタイトルを出力する。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  import requests import time from bs4 import BeautifulSoup def anaylise_ranking_books(html): soup = BeautifulSoup(html.</description>
    </item>
    
    <item>
      <title>VundleでVimのプラグインを簡単管理</title>
      <link>https://wenhan.blog/post/manage-vim-plugins-with-vundle/</link>
      <pubDate>Mon, 21 Nov 2016 00:37:36 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/manage-vim-plugins-with-vundle/</guid>
      <description>Vimのプラグインを管理する人気のツール、Vundleの利用メモ
本家のサイト：[https://github.com/VundleVim/Vundle.vim]
Vundleを利用するメリット
 プラグインを.vimrcでインストール/更新/削除できる 名前だけ書けば自動で探してくれる  インストール 以下のコマンドで、ファイルをコピーするだけでインストール完了
1  $ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim   設定 以下の設定内容を.vimrcのトップに記入する。 説明のためいくつかの行がイメージになっている。 実際利用するときにコメントアウトする必要がある。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  set nocompatible &amp;#34; be iMproved, requiredfiletype off &amp;#34; required&amp;#34; set the runtime path to include Vundle and initializeset rtp+=~/.</description>
    </item>
    
    <item>
      <title>PythonでGoogle maps のapiを利用する</title>
      <link>https://wenhan.blog/post/google-maps-api-with-python/</link>
      <pubDate>Sat, 12 Nov 2016 01:22:46 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/google-maps-api-with-python/</guid>
      <description>PythonでGoogle mapsのAPI を利用しルート検索をやってみた。
利用するモジュールはgooglemaps/google-maps-services-python
環境構築は以下のコマンドでOK, ついでにipythonもインストールする。
1 2  $ pip install googlemaps $ pip install ipython   あと、GoogleのAPIキーの申請が必要なので、Google APIsで申請＆有効にする。
ここまで問題なかったら、早速使ってみよう。 戸塚駅から踊場駅まで、車のルート情報を取得
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79  $ ipython Python 3.</description>
    </item>
    
    <item>
      <title>iPhoneでGoogleマップを表示する時のメモ</title>
      <link>https://wenhan.blog/post/googlemap-on-ios/</link>
      <pubDate>Tue, 01 Nov 2016 01:16:21 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/googlemap-on-ios/</guid>
      <description>GoogleマップをiPhone上に表示したい時にはまったことを残す。
Google Maps API &amp;gt; iOS向け &amp;gt; Maps SDK for iOSを参考に、とりあえず画面上GoogleMapを表示させようの所、画面が真っ白で何も表示されない。
そして、コンソールには以下のエラーメッセージが出ていた。
1  ClientParametersRequest failed, 0 attempts remaining (0 vs 6). Error Domain=com.google.HTTPStatus Code=400   ネットで調べたところ、このサイトを見つけた。 そして自分の場合は、三つ目の見直しで、自分のAPIキーが「無効」になっている。。
このエラーの原因は、だいたいAPIキーの設定に何か間違っているようです。 以下の見直しを確認すべき。
 APIキーを生成するとき、xcodeのProjectのbundle IDを設定した方がいい。このパラメータは「任意」ってGoogleが言ったが、やはり設定した方が無難。 アプリのBundleIDを変更した場合、APIキーを再生成しましょう。 Google Developersのダッシュボードで「Google Maps SDK for iOS」が有効になっていることを確認しましょう。デフォルトでは無効になっている。(今回はここにはまった)  時間があったらAPIキー有効の画面もアップする予定</description>
    </item>
    
    <item>
      <title>Pythonで回文チェック</title>
      <link>https://wenhan.blog/post/python-reverse-str-to-check-palindrome/</link>
      <pubDate>Sat, 29 Oct 2016 01:21:18 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/python-reverse-str-to-check-palindrome/</guid>
      <description>もう一題をやった。Palindrome chain length
回文に関する計算問題です。 回文とは、文字列を真ん中で割って、左辺と右辺が反転的に対称している文字列のこと。 例えば、「あいういあ」が回文であり、「あいうえお」が回文では無い。 数字の場合も同じく、5,44,171,4884が回文であり、43,194,4773が回文ではない。
そして、今回の問題は、引数の数字に対し、特定な計算方法で、何回計算したら回文になるかを算出する。 ここでの特定な計算方法は、「自分の数字の各桁を反転し、元の数字と足し算する」のこと。
例えば、87が与えられ、4回の計算で回文数字になったため、戻り値を４にする。
1 2 3 4  87 + 78 = 165; 165 + 561 = 726; 726 + 627 = 1353; 1353 + 3531 = 4884;   ここで難しいのは、数字をどうやって反転するか。 いろいろ調べた結果、意外と簡単でした。しかも一行で済む。Python で文字列反転
1 2  str(n) # 数字を文字列に変換 str(n)[::-1] # 数字を文字列に変換し、逆順に変換する。   このような書き方は、「文字列の末尾から一つずつ遡って先頭まで要素を取り出す」の操作となる。
そしてさっきの問題に対し自分の答えは
1 2 3 4 5 6  def palindrome_chain_length(n): cnt=0 while str(n) != str(n)[::-1] : cnt += 1 n += int(str(n)[::-1]) return cnt   いや〜便利だな〜これで今日もよく寝れる〜</description>
    </item>
    
    <item>
      <title>Pythonの出力フォーマット</title>
      <link>https://wenhan.blog/post/python-print-format/</link>
      <pubDate>Sat, 29 Oct 2016 00:28:06 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/python-print-format/</guid>
      <description>今日もCodeWarの問題を練習した。RGB To Hex Conversion
問題を簡略化にすると、rgbの数字を16進に変換し出力する。
1 2 3 4  rgb(255, 255, 255) # returns FFFFFF rgb(255, 255, 300) # returns FFFFFF rgb(0,0,0) # returns 000000 rgb(148, 0, 211) # returns 9400D3   直接hexで変換すると、”0x”が余計についているし、&amp;ldquo;00&amp;quot;が&amp;quot;0&amp;quot;になる。 sprintf見たいな関数が無いかなっと思いながら、このサイトを見つけた。 Cのsprintfのような文字列フォーマット
なんと、フォーマットを指定すれば数字が直接変換される！桁数の指定も出来る。
そして自分の答えは
1 2 3 4 5  def limit(a): return min(max(a, 0), 255) def rgb(r, g, b): return &amp;#34;%02X%02X%02X&amp;#34; % (limit(r), limit(g), limit(b),)   便利だな~</description>
    </item>
    
    <item>
      <title>Hexoをインストール</title>
      <link>https://wenhan.blog/post/install-of-hexo/</link>
      <pubDate>Mon, 24 Oct 2016 23:15:49 +0000</pubDate>
      
      <guid>https://wenhan.blog/post/install-of-hexo/</guid>
      <description>ここのURLを参考しながら、HexoのBlogを設定した。 https://liginc.co.jp/web/programming/server/104594
Install の途中で、以下のエラーが出た。
1 2  % hexo deploy ERROR Deployer not found: github   https://github.com/hexojs/hexo/issues/1040 を参考にして、直した。
1  % npm install hexo-deployer-git --save   _config.ymlのtypeもgitに変更
1 2  deploy:type:git  MarkDownの文法も勉強せねばな。。。やることが多い〜</description>
    </item>
    
    
    
  </channel>
</rss>
